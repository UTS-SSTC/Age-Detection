<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Age Detection Web Interface</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(to right, #f0f4f8, #d9e2ec);
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        h1 {
            margin-top: 30px;
            color: #2b2d42;
            font-size: 2.8rem;
        }

        .instructions {
            margin-top: 10px;
            margin-bottom: 20px;
            font-size: 1.1rem;
            color: #444;
        }

        .container {
            display: flex;
            flex-direction: row;
            justify-content: center;
            align-items: flex-start;
            gap: 40px;
            margin-top: 30px;
        }

        .video-section, .control-section {
            background-color: #ffffff;
            padding: 30px;
            border-radius: 20px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
        }

        #video-container {
            position: relative;
            width: 640px;
            height: 480px;
        }

        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            border-radius: 16px;
        }

        video {
            width: 640px;
            height: 480px;
            z-index: 1;
        }

        canvas {
            width: 640px;
            height: 480px;
            z-index: 2;
        }

        .control-section {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        select, button {
            padding: 12px 24px;
            margin: 12px;
            font-size: 18px;
            border-radius: 10px;
            border: 1px solid #ccc;
            outline: none;
            width: 220px;
        }

        button {
            background-color: #007bff;
            color: #fff;
            border: none;
            transition: background-color 0.3s ease;
            cursor: pointer;
        }

        button:hover {
            background-color: #0056b3;
        }

        #result {
            font-size: 20px;
            color: #333;
            margin-top: 20px;
        }
    </style>
</head>
<body>

<h1>Age Detection</h1>

<div class="instructions">
    Allow camera access → Choose a model → Click the button to predict age
</div>

<div class="container">
    <!-- Webcam feed with overlay canvas -->
    <div class="video-section">
        <div id="video-container">
            <video id="webcam" autoplay muted></video>
            <canvas id="overlay"></canvas>
        </div>
    </div>

    <!-- Controls -->
    <div class="control-section">
        <select id="model-select">
            <option value="efficientnet_b0">EfficientNet-B0</option>
            <option value="efficientnet_b4">EfficientNet-B4</option>
            <option value="resnet_50">ResNet-50</option>
            <option value="resnext_101">ResNeXt-101</option>
        </select>
        <button onclick="captureAndSend()">Capture & Predict</button>
        <div id="result"></div>
    </div>
</div>

<script>
    const video = document.getElementById("webcam");
    const overlay = document.getElementById("overlay");
    const canvasCtx = overlay.getContext("2d");

    async function setupCameraAndFace() {
        await faceapi.nets.tinyFaceDetector.loadFromUri("https://cdn.jsdelivr.net/npm/face-api.js/models");

        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        video.srcObject = stream;

        video.addEventListener("playing", () => {
            overlay.width = video.videoWidth;
            overlay.height = video.videoHeight;

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
                canvasCtx.clearRect(0, 0, overlay.width, overlay.height);
                detections.forEach(d => {
                    const box = d.box;
                    canvasCtx.strokeStyle = "#FF0000";
                    canvasCtx.lineWidth = 2;
                    canvasCtx.strokeRect(box.x, box.y, box.width, box.height);
                });
            }, 100);
        });
    }

    setupCameraAndFace();

    function captureAndSend() {
        const canvas = document.createElement("canvas");
        canvas.width = video.videoWidth || 640;
        canvas.height = video.videoHeight || 480;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const imageData = canvas.toDataURL("image/jpeg");
        const selectedModel = document.getElementById("model-select").value;

        fetch("/predict", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ image: imageData, model: selectedModel })
        })
        .then(response => response.json())
        .then(data => {
            document.getElementById("result").innerText =
                data.age ? `Predicted Age: ${data.age}` : "Prediction failed.";
        })
        .catch(error => {
            console.error("Prediction failed:", error);
            document.getElementById("result").innerText = "Prediction failed.";
        });
    }
</script>

</body>
</html>
